{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free Lime Prediction 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob as glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "#%matplotlib inline\n",
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laden der Prozessdaten und der INSPECT-Daten jeweils in eigene Dataframes (TimeTables). Falls die .xlsx-Dateien bereits einmal gelesen wurden, besteht jeweils eine .pkl-Datei, die sich schneller einlesen lässt. Es handelt sich bei den Prozessdaten um die Rohdaten, die noch nicht vorverarbeitet wurden. Bei den INSPECT-Daten wird ein Resampling auf die PLS-Frequenz von einer Minute durchgeführt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Control Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfad anpassen\n",
    "path = 'C:/Users/fw3476/bwSyncAndShare/Privat/Projekte/Freikalk/Daten_Freikalk/Prozessparameter'\n",
    "#path = 'C:/Users/patrick.waibel/bwSyncAndShare/Privat/Projekte/Freikalk/Daten_Freikalk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_quality_values(df):\n",
    "    \n",
    "    #df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Nur neue Freikalk-Werte berücksichtigen\n",
    "    df['Diff'] = df['fCaO'].diff()\n",
    "    df.loc[df.Diff == 0, df.select_dtypes(include=['float64']).columns] = np.nan\n",
    "    df.loc[df.Diff.diff().notna(),df.select_dtypes(include=['float64']).columns] = np.nan\n",
    "    \n",
    "    # Freikalk-Werte sind größer Null\n",
    "    df.loc[df.fCaO == 0, df.select_dtypes(include=['float64']).columns]= np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/fw3476/bwSyncAndShare/Privat/Projekte/Freikalk/Daten_Freikalk/Prozessparameter\\\\2017_03_07-2017_04_01 Prozessparameter.xlsx']\n"
     ]
    }
   ],
   "source": [
    "# Check for existing database\n",
    "pklProcessData = glob.glob(path + \"/Prozessparameter_Korr/processData.pkl\")\n",
    "#pklProcessData = None\n",
    "\n",
    "if pklProcessData:\n",
    "    df_PLS = pd.read_pickle(pklProcessData[0])\n",
    "else:\n",
    "    \n",
    "    excelFiles = glob.glob(path + \"/*.xlsx\")\n",
    "\n",
    "    print(excelFiles)\n",
    "\n",
    "    df_Brennstoff = pd.DataFrame()\n",
    "    df_Prozessparameter = pd.DataFrame()\n",
    "    df_Brennereinstellungen = pd.DataFrame()\n",
    "    df_Qualitaet = pd.DataFrame()\n",
    "\n",
    "    list_Brennstoff_ = []\n",
    "    list_Prozessparameter_ = []\n",
    "    list_Brennereinstellungen_ = []\n",
    "    list_Qualitaet_ = []\n",
    "\n",
    "    for file_ in excelFiles:\n",
    "        df_Brennstoff = pd.read_excel(file_,index_col=None, header=0, skiprows=[0,1,2,4,5],\\\n",
    "                                      sheet_name='Brennstoffzusammensetzungen')  \n",
    "        df_Prozessparameter = pd.read_excel(file_,index_col=None, header=0, skiprows=[0,1,2,4,5], sheet_name='Prozessparameter')\n",
    "        df_Brennereinstellungen = pd.read_excel(file_,index_col=None, header=0, skiprows=[0,1,2,4,5], sheet_name='Brennereinstellungen')\n",
    "        df_Qualitaet = pd.read_excel(file_,index_col=None, header=0, skiprows=[0,1,2,4,5], sheet_name='Qalitätsparameter')\n",
    "\n",
    "        df_Brennstoff.rename(columns = {'Unnamed: 1':'Zeit'}, inplace=True)\n",
    "        df_Prozessparameter.rename(columns = {'Unnamed: 1':'Zeit'}, inplace=True)\n",
    "        df_Brennereinstellungen.rename(columns = {'Unnamed: 1':'Zeit'}, inplace=True)\n",
    "        #df_Qualitaet.rename(columns={df.columns[1]: 'Zeit' })\n",
    "        df_Qualitaet.rename(columns = {'Unnamed: 1':'Zeit'}, inplace=True)\n",
    "\n",
    "        list_Brennstoff_.append(df_Brennstoff)\n",
    "        list_Prozessparameter_.append(df_Prozessparameter)\n",
    "        list_Brennereinstellungen_.append(df_Brennereinstellungen)\n",
    "        list_Qualitaet_.append(df_Qualitaet)\n",
    "\n",
    "    df_Brennstoff = pd.concat(list_Brennstoff_, axis=0, sort=True )\n",
    "    df_Prozessparameter = pd.concat(list_Prozessparameter_, axis=0, sort=True)\n",
    "    df_Brennereinstellungen = pd.concat(list_Brennereinstellungen_, axis=0, sort=True)\n",
    "    df_Qualitaet = pd.concat(list_Qualitaet_, axis=0, sort=True)\n",
    "    \n",
    "    #df_Brennstoff = df_Brennstoff.reset_index(drop=True)\n",
    "    #df_Prozessparameter = df_Prozessparameter.reset_index(drop=True)\n",
    "    #df_Brennereinstellungen = df_Brennereinstellungen.reset_index(drop=True)\n",
    "    #df_Qualitaet = df_Qualitaet.reset_index(drop=True)\n",
    "    \n",
    "    correct_quality_values(df_Qualitaet)\n",
    "\n",
    "    df_Brennstoff.set_index('Zeit', inplace=True)\n",
    "    df_Prozessparameter.set_index('Zeit', inplace=True)\n",
    "    df_Brennereinstellungen.set_index('Zeit', inplace=True)  \n",
    "    df_Qualitaet.set_index('Zeit', inplace=True)\n",
    "    \n",
    "    #Qualitaet_Columns = list(df_Qualitaet.columns.values)\n",
    "\n",
    "    df_PLS = pd.concat([df_Brennstoff, df_Prozessparameter, df_Brennereinstellungen, df_Qualitaet], axis = 1)\n",
    "\n",
    "    del [[df_Brennstoff, df_Prozessparameter, df_Brennereinstellungen, df_Qualitaet]]\n",
    "\n",
    "    df_PLS = df_PLS.drop(list(df_PLS.filter(regex = 'Unnamed')), axis = 1)\n",
    "\n",
    "    # Write Dataframe to file    \n",
    "    df_PLS.to_pickle(path + \"/processData.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_Qualitaet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ae060fff319f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_Qualitaet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_Qualitaet' is not defined"
     ]
    }
   ],
   "source": [
    "df_Qualitaet.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSPECT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pklInspectData = glob.glob(path + \"/InspectData.pkl\")\n",
    "\n",
    "if pklInspectData:\n",
    "\n",
    "    df_INSPECT = pd.read_pickle(pklInspectData[0])\n",
    "\n",
    "else:\n",
    "\n",
    "    allFilesInspect = glob.glob(path + \"/INSPECT/*.xls\")\n",
    "\n",
    "    df_INSPECT = pd.DataFrame()\n",
    "    list_INSPECT = []\n",
    "\n",
    "    for file_ in allFilesInspect:\n",
    "        INSPECT_Single = pd.read_excel(file_,index_col=None, header=0)  \n",
    "        list_INSPECT.append(INSPECT_Single)\n",
    "\n",
    "    df_INSPECT = pd.concat(list_INSPECT, axis=0, sort=True)   \n",
    "\n",
    "    df_INSPECT.set_index('TIME_STAMP', inplace=True)\n",
    "\n",
    "    # Resampling to PCS data sample rate\n",
    "    df_INSPECT = df_INSPECT.resample('Min').mean()\n",
    "    \n",
    "    # Write Dataframe to file    \n",
    "    df_INSPECT.to_pickle(path + \"/InspectData.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_INSPECT.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging of both data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_PLS, df_INSPECT, how='outer', left_index=True, right_index=True)\n",
    "df.info()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove NaT rows from data\n",
    "print(f\"The data size before removing NaT is : {df.shape} \")\n",
    "df = df[df.index.notnull()]\n",
    "print(f\"The data size after removing NaT is : {df.shape} \")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Shift of Free Lime Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time offset in minutes\n",
    "time_offset = -45\n",
    "\n",
    "# shift fCaO values with time_offset to get target values\n",
    "fCaO_target = df['fCaO'].copy()\n",
    "fCaO_target.index = fCaO_target.index.shift(time_offset, freq='Min')\n",
    "fCaO_target = fCaO_target.to_frame()\n",
    "fCaO_target.rename(index=str, columns={\"fCaO\": \"fCaO_target\"}, inplace=True)\n",
    "\n",
    "# Inner merge with original dataframe \n",
    "df = pd.merge(df,fCaO_target, how='inner', left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of fCaO-value\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "#ax1.plot(df.fCaO)\n",
    "ax1.plot(df.fCaO_target)\n",
    "\n",
    "fig1.autofmt_xdate()\n",
    "#CaO_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.where(df.index.isna())\n",
    "#np.sum(df_merged.index.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.merge(df,fCaO, how='outer', left_index=True, right_index=True)\n",
    "#print(\"The data size before removing NaT is : {} \".format(df.shape)) \n",
    "\n",
    "#np.sum(df_original.index.notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(fCaO.isnull())\n",
    "#np.sum(df.fCaO.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.index[:5]\n",
    "#df_INSPECT.index[:5]\n",
    "#df_INSPECT.asfreq(freq='1Min')\n",
    "#df_INSPECT.index[:5]\n",
    "#pd.infer_freq(df_INSPECT.index)\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots()\n",
    "##ax.plot(df2['fCaO_Filtered'])\n",
    "#ax.plot(df['fCaO_Shifted'])\n",
    "#ax.plot(df['fCaO'])\n",
    "#fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "\n",
    "# Drop all rows with free lime value of 0\n",
    "#df2.drop(df2[df2['fCaO_target'] == 0].index, inplace=True)\n",
    "\n",
    "\n",
    "df2['fCaO_hold'] = df2['fCaO']\n",
    "\n",
    "\n",
    "# find new lab values of free lime\n",
    "df2['Diff'] = df2['fCaO_target'].diff()\n",
    "df2.loc[df2.Diff == 0,'fCaO_target']= np.nan\n",
    "\n",
    "df2['Diff1'] = df2['fCaO'].diff()\n",
    "df2.loc[df2.Diff1 == 0,'fCaO']= np.nan\n",
    "\n",
    "# Set all rows with free lime value of 0 to NaN\n",
    "df2['fCaO_target'] = df2['fCaO_target'].replace(0, np.nan)\n",
    "df2['fCaO'] = df2['fCaO'].replace(0, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "#idx3 = df2.loc[df2.DiffDiff > 0,'Diff']\n",
    "\n",
    "\n",
    "\n",
    "print(np.sum(df2.fCaO_target.isna()))\n",
    "\n",
    "df2['fCaO_target_filtered'] = df2['fCaO_target'].interpolate(method='time')\n",
    "\n",
    "\n",
    "#df2.drop(['Diff'], inplace=True)\n",
    "\n",
    "print(np.sum(df2.fCaO_target_filtered.isna()))\n",
    "\n",
    "#df2.drop(df2[df2.fCaO_target_filtered.isna()].index, axis=0, inplace=True)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.fCaO.diff()[df.fCaO.diff() != 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of fCaO-value\n",
    "#\n",
    "fig2, ax2 = plt.subplots()\n",
    "#ax2.plot(df.fCaO)\n",
    "ax2.plot(df2.fCaO_target)\n",
    "\n",
    "\n",
    "fig2.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.Diff.head(5)\n",
    "#print(np.sum(df2.fCaO_Filtered.isnull()))\n",
    "#print(np.sum(df2.fCaO_Filtered_Interpol.isnull()))\n",
    "#df2.loc[df2.Diff == 0,'fCaO_Filtered'] = np.nan\n",
    "#print(df2.fCaO_Filtered.sum())\n",
    "#df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = df2.fillna(method='bfill',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots()\n",
    "##ax.plot(df2['fCaO_Filtered'])\n",
    "#ax.plot(df2['fCaO_Filtered'])\n",
    "#fig.autofmt_xdate()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots()\n",
    "\n",
    "#plt.matshow(df2.iloc[:,:10].corr())\n",
    "\n",
    "#cax = ax1.matshow(df2.iloc[:,-10:].corr(), interpolation='nearest')\n",
    "cax = ax1.matshow(df2.iloc[:,:].corr(), interpolation='nearest')\n",
    "fig1.colorbar(cax)\n",
    "\n",
    "df_corr = df2.iloc[:,:].corr()\n",
    "df_corr.loc[:,'fCaO_target']\n",
    "\n",
    "idx = np.abs(df_corr.loc[:,'fCaO_target'])>0.05\n",
    "\n",
    "df_corr.loc[idx,'fCaO_target'].abs().sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "#\n",
    "#corr = df.corr()\n",
    "#\n",
    "#fig5, ax5 = plt.subplots()\n",
    "#ax5 = sns.heatmap(corr, \n",
    "#            xticklabels=corr.columns.values,\n",
    "#            yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Splits\n",
    "Zwei Varianten zur Aufteilung in Training-/Testsets sind möglich:\n",
    "1. Trainingsdatensätze bauen zeitlich aufeinander auf und werden damit größer (1, 1+2, 1+2+3,...). Die Test-Set-Länge bleibt konstant. Hier sollte das Ergebnis bei der Validierung eigentlich kontinuierlich besser werden. (split_variant = 0)\n",
    "2. Trainingsdatensätze besitzen eine konstante Länge. (split_variant = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_variant = 1\n",
    "n_splits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "if split_variant == 0:\n",
    "\n",
    "    splits = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    train = []\n",
    "    test = []\n",
    "\n",
    "    for train_index, test_index in splits.split(df2):\n",
    "\n",
    "        train_new = df2.iloc[train_index]\n",
    "        test_new = df2.iloc[test_index]\n",
    "\n",
    "        print('Observations: %d' % (len(train_new) + len(test_new)))\n",
    "        print('Training Observations: %d' % (len(train_new)))\n",
    "        print('Testing Observations: %d' % (len(test_new)))\n",
    "\n",
    "        train.append(train_new)\n",
    "        test.append(test_new)\n",
    "        #split_variant == 1\n",
    "else: \n",
    "\n",
    "    #max_train_size = len(df2)//n_splits\n",
    "    max_train_size = 15832\n",
    "    \n",
    "    splits = TimeSeriesSplit(n_splits=n_splits, max_train_size = max_train_size)\n",
    "\n",
    "    train = []\n",
    "    test = []\n",
    "\n",
    "    for train_index, test_index in splits.split(df2):\n",
    "\n",
    "        train_new = df2.iloc[train_index]\n",
    "        test_new = df2.iloc[test_index]\n",
    "\n",
    "        print('Observations: %d' % (len(train_new) + len(test_new)))\n",
    "        print('Training Observations: %d' % (len(train_new)))\n",
    "        print('Testing Observations: %d' % (len(test_new)))\n",
    "\n",
    "        train.append(train_new)\n",
    "        test.append(test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3, ax3 = plt.subplots()\n",
    "ax3.plot(train[3].fCaO_target_filtered)\n",
    "ax3.plot(test[3].fCaO_target_filtered)\n",
    "fig3.autofmt_xdate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktion zur Bewertung der Prädiktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(y_pred, y):\n",
    "    return np.nanmean(np.abs(y_pred-y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Predictor\n",
    "Erstellen von simplen Prädiktionen zur Bewertung des Prädiktionsverfahrens:\n",
    "1. Wert der letzten verfügbaren Messung\n",
    "2. Lineare Prädiktion aus den letzten beiden Messungen\n",
    "3. Polynomiale/quadratische Prädiktion aus den letzten drei Messungen\n",
    "4. Einfacher Mittelwert der Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Wert der letzten verfügbaren Messung\n",
    "\n",
    "scores = []\n",
    "\n",
    "for idx, _test in enumerate(test):\n",
    "    X = test[idx].fCaO_hold.values\n",
    "    y = test[idx].fCaO_target.values\n",
    "    \n",
    "    y_pred = X\n",
    "    \n",
    "    score = get_score(y_pred, y)\n",
    "    \n",
    "    print(score)\n",
    "    scores.append(score)\n",
    "    \n",
    "print(f\"Overall average score: {np.mean(scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Lineare Prädiktion aus den letzten beiden Messungen\n",
    "\n",
    "scores = []\n",
    "\n",
    "\n",
    "for idx, _train in enumerate(train):\n",
    "    X = train[idx].fCaO.values\n",
    "    y = train[idx].fCaO_target.values\n",
    "    \n",
    "    y_pred = np.full([len(X)], np.nan)\n",
    "    #y_pred = np.arange(len(X))\n",
    "    # y_pred.fill(np.nan)\n",
    "    \n",
    "    y_pred[1:] = X[1:]+ X[1:]-X[:-1]\n",
    "    \n",
    "    score = get_score(y_pred, y)\n",
    "    \n",
    "    print(score)\n",
    "    scores.append(score)\n",
    "    \n",
    "print(f\"Overall average score: {np.mean(scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3, ax3 = plt.subplots()\n",
    "ax3.plot(df2.fCaO.values)\n",
    "ax3.plot(df2.fCaO_target.values)\n",
    "fig3.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3, ax3 = plt.subplots()\n",
    "ax3.plot(y_pred)\n",
    "ax3.plot(y,'*')\n",
    "fig3.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramm\n",
    "fig3, ax3 = plt.subplots()\n",
    "ax3.hist(df2.fCaO_target,bins=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Mittelwert der Trainingsdaten\n",
    "\n",
    "scores = []\n",
    "\n",
    "\n",
    "for idx, _train in enumerate(train):\n",
    "    X = train[idx].fCaO.values\n",
    "    y = test[idx].fCaO_target.values\n",
    "\n",
    "    fCaO_mean = np.nanmean(X)\n",
    "    y_pred = np.full([len(y)], fCaO_mean)\n",
    " \n",
    "    score = get_score(y_pred, y)\n",
    "    \n",
    "    print(score)\n",
    "    scores.append(score)\n",
    "    \n",
    "print(f\"Overall average score: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code nur bis hier \"sinnvoll\" [Patrick 2019/07/04]\n",
    "\n",
    "----------------------------------------------------------------------------------------------\n",
    "### Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Qualitaet_Columns = df.columns[36:57].values\n",
    "#dropCols = Qualitaet_Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropCols2 = list(df2.filter(regex = 'Tmp'))\n",
    "#dropCols = ['fCaO','fCaO_Shifted','fCaO_Filtered','Swirl','Energieeintrag','Alit']\n",
    "#dropCols = dropCols + dropCols2\n",
    "#df3 = df2.drop(dropCols, axis=1)\n",
    "#df3.info()\n",
    "\n",
    "#Qualitaet_Columns.remove('Unnamed: 0')\n",
    "#Qualitaet_Columns.remove('Unnamed: 12')\n",
    "\n",
    "#dropCols = df2.columns[:-35]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "isLog = True\n",
    "\n",
    "dropCols = ['fCaO','fCaO_Shifted','fCaO_Filtered','Swirl','Energieeintrag','Alit']\n",
    "#dropCols2 = list(df2.filter(regex = 'Tmp'))\n",
    "dropCols2 = list(df2.columns[:-68].values)\n",
    "dropCols2 = list(Qualitaet_Columns)\n",
    "\n",
    "dropCols = dropCols + dropCols2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#X = df.drop('fCaO', axis=1)\n",
    "#X = merge[['fCaO_x','Temperatur Rauchkammer']].fillna(method='bfill').values\n",
    "\n",
    "# Zu entfernen\n",
    "#df2 = df2.dropna(axis=0)\n",
    "\n",
    "df_train = df2[:'2017-04-21']\n",
    "df_test = df2['2017-04-22':]\n",
    "\n",
    "\n",
    "X_train = df_train.drop(dropCols, axis=1).fillna(method='bfill').values\n",
    "X_test = df_test.drop(dropCols, axis=1).fillna(method='bfill').values\n",
    "\n",
    "\n",
    "y_train = df_train['fCaO_Filtered'].fillna(method='bfill').values.reshape(-1,1)\n",
    "y_test = df_test['fCaO_Filtered'].fillna(method='bfill').values.reshape(-1,1)\n",
    "\n",
    "\n",
    "#X = df2[['Tmp_Trapez']].fillna(method='bfill').values.reshape(-1,1)\n",
    "#merge.fillna(method='bfill').isna().sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if isLog:\n",
    "    y_train = np.log(y_train)    \n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(np.isnan(X_train.any()))\n",
    "print(np.isnan(y_train.any()))\n",
    "\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "\n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "if not isLog:\n",
    "    ax2.plot(y_test)\n",
    "    ax2.plot(y_pred, alpha = 0.5)\n",
    "else:\n",
    "    ax2.plot(df_test.index, y_test)\n",
    "    ax2.plot(df_test.index, np.exp(y_pred), alpha = 0.5)\n",
    "    \n",
    "fig2.autofmt_xdate()\n",
    "plt.plot\n",
    "\n",
    "\n",
    "if not isLog:\n",
    "    print(mean_absolute_error(y_test, y_pred))\n",
    "else:\n",
    "    print(mean_absolute_error(y_test, np.exp(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = np.ones(len(y_test))*np.mean(y_train)\n",
    "\n",
    "if not isLog:\n",
    "    print('Baseline prediction error (Mean): {}'.format(mean_absolute_error(y_test, y_mean)))\n",
    "else:\n",
    "    print('Baseline prediction error (Mean): {}'.format(mean_absolute_error(y_test, np.exp(y_mean))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test[df_test.fCaO.isna()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.fCaO.fillna(method='bfill')\n",
    "\n",
    "y_last = df_test.loc[:,'fCaO'].values\n",
    "\n",
    "if not isLog:\n",
    "    print('Baseline prediction error (Last fCaO value): {}'.format(mean_absolute_error(y_test, y_last)))\n",
    "else:\n",
    "    print('Baseline prediction error (Last fCaO value): {}'.format(mean_absolute_error(y_test, y_last)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramm of target (fCaO)\n",
    "\n",
    "Either log or normal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2['fCaO_Shifted'].isnull().sum()\n",
    "\n",
    "fig3, ax3 = plt.subplots()\n",
    "ax3.hist(y_test,bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "clf.fit(X,y)\n",
    "predictions2 = lm.predict(X)\n",
    "\n",
    "\n",
    "\n",
    "if not isLog:\n",
    "    print(mean_absolute_error(y, predictions))\n",
    "else:\n",
    "    print(mean_absolute_error(np.exp(y), np.exp(predictions)))\n",
    "\n",
    "#print(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = np.abs(clf.coef_)\n",
    "index = fi.argmax(axis=0)\n",
    "\n",
    "#indices = np.argwhere(fi>0.7*fi.max())\n",
    "\n",
    "\n",
    "indices = np.argsort(fi)[::-1]\n",
    "plt.figure(figsize=(20, 14))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), fi[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "#plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xticks(range(X.shape[1]), list(df2.drop(['fCaO','fCaO_Shifted','Swirl','Energieeintrag'], axis=1).columns[indices]))\n",
    "#plt.xlabel(list(X.columns[indices]))\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Fit regression model\n",
    "regr_1 = DecisionTreeRegressor(max_depth=2)\n",
    "regr_2 = DecisionTreeRegressor(max_depth=5)\n",
    "regr_1.fit(X, y)\n",
    "regr_2.fit(X, y)\n",
    "\n",
    "\n",
    "regr_1.fit(X, y)\n",
    "regr_2.fit(X, y)\n",
    "\n",
    "\n",
    "y_1 = regr_1.predict(X)\n",
    "y_2 = regr_2.predict(X)\n",
    "\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "\n",
    "ax2.plot(y)\n",
    "ax2.plot(y_1)\n",
    "ax2.plot(y_2)\n",
    "\n",
    "print(mean_absolute_error(y, y_1))\n",
    "print(mean_absolute_error(y, y_2))\n",
    "\n",
    "# Plot the results\n",
    "#plt.figure()\n",
    "#plt.scatter(X, y, s=20, edgecolor=\"black\",\n",
    "#            c=\"darkorange\", label=\"data\")\n",
    "#plt.plot(X, y_1, color=\"cornflowerblue\",\n",
    "#         label=\"max_depth=2\", linewidth=2)\n",
    "#plt.plot(X, y_2, color=\"yellowgreen\", label=\"max_depth=5\", linewidth=2)\n",
    "#plt.xlabel(\"data\")\n",
    "#plt.ylabel(\"target\")\n",
    "#plt.title(\"Decision Tree Regression\")\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "463px",
    "left": "1075px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
